# -*- coding: utf-8 -*-
"""graph_last.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13gXpUczPw3Ji3FshzR1jkjcfcdGAsocq
"""

# --- Colab: mount Drive (safe to re-run) ---
try:
    from google.colab import drive  # type: ignore
    drive.mount('/content/drive', force_remount=True)
except Exception as _:
    pass

import os, sys, math, time, csv, random, io, re, json
from typing import List, Dict, Tuple, Any, Optional, Iterable, Set
import torch
from torch import nn
from torch.nn import functional as F

# --- Base paths (auto-detect, no layout changes) ---
BASE_DRIVE = "/content/drive/MyDrive/Project"
BASE_WIN   = r"D:\graphmatch-ai\Beta_0_2"
BASE = BASE_DRIVE if os.path.isdir(BASE_DRIVE) else (BASE_WIN if os.path.isdir(BASE_WIN) else BASE_DRIVE)

STAGE2 = os.path.join(BASE, "stage2_out")
STAGE3 = os.path.join(BASE, "stage3_out")
STAGE4 = os.path.join(BASE, "stage4_out")

# --- Inputs (unchanged names) ---
TFIDF_J2R = os.path.join(STAGE2, "job_to_resumes_top10_tfidf.csv")
BM25_J2R  = os.path.join(STAGE2, "job_to_resumes_top10_bm25.csv")
LABELS    = os.path.join(BASE, "labels_clean_top10_strict.csv")  # job_id,resume_id,label

# --- Outputs (new, alongside your layout) ---
OUT_LGCN_J2R  = os.path.join(STAGE2, "job_to_resumes_top10_lightgcn.csv")
OUT_LGCN_R2J  = os.path.join(STAGE2, "resume_to_jobs_top10_lightgcn.csv")
OUT_SAGE_J2R  = os.path.join(STAGE2, "job_to_resumes_top10_graphsage.csv")
OUT_SAGE_R2J  = os.path.join(STAGE2, "resume_to_jobs_top10_graphsage.csv")
OVERALL_TRUE  = os.path.join(STAGE2, "overall_metrics_true.csv")

os.makedirs(STAGE2, exist_ok=True)
os.makedirs(STAGE3, exist_ok=True)
os.makedirs(STAGE4, exist_ok=True)

# --- Device (expecting L4; any CUDA is fine) ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

# >>> ANCHOR:GM/GRAPHMATCH/PRE-FLIGHT/2025-08-27/1a9f

# Quick pre-flight (after Drive mount & path definitions)
import torch, os
print("CUDA available:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("GPU:", torch.cuda.get_device_name(0))

need = [TFIDF_J2R, BM25_J2R, LABELS]
print({os.path.basename(p): os.path.isfile(p) for p in need})
print("n_jobs (estimated after load) and n_res will print once the script runs.")

if torch.cuda.is_available():
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.allow_tf32 = True
    try:
        torch.set_float32_matmul_precision("medium")  # PyTorch ≥ 2.0
    except Exception:
        pass

def read_csv_rows(path: str, sep: Optional[str] = None) -> List[Dict[str,str]]:
    rows: List[Dict[str,str]] = []
    if not path or not os.path.isfile(path):
        return rows
    with open(path, "r", encoding="utf-8-sig", newline="") as f:
        sample = f.read(65536)
        f.seek(0)
        first = f.readline()
        sep_hint = None
        if first.lower().startswith("sep="):
            raw = first.strip()[4:]
            sep_hint = "\t" if raw in ("\\t","\t") else (raw[:1] if raw else None)
        else:
            f.seek(0)
        if sep is not None:
            delim = "\t" if sep == r"\t" else sep
        elif sep_hint:
            delim = sep_hint
        else:
            try:
                dialect = csv.Sniffer().sniff(sample, delimiters=[",","\t",";","|"])
                delim = dialect.delimiter
            except Exception:
                delim = ","
        rdr = csv.DictReader(f, delimiter=delim)
        for r in rdr:
            rows.append({(k if k is not None else ""): ("" if v is None else str(v)) for k,v in r.items()})
    return rows

def write_csv_rows(path: str, rows: List[Dict[str,Any]], header: List[str], sep: str = ","):
    with open(path,"w",encoding="utf-8-sig",newline="") as f:
        w = csv.DictWriter(f, fieldnames=header, delimiter=sep)
        w.writeheader()
        for r in rows:
            w.writerow({k: ("" if r.get(k) is None else r.get(k)) for k in header})

# Load implicit positives from TF-IDF/BM25 top-10s (treated as interactions)
def load_interactions(j2r_paths: List[str]) -> Tuple[Set[Tuple[str,str]], Set[str], Set[str], Dict[str,List[str]]]:
    edges: Set[Tuple[str,str]] = set()
    jobs: Set[str] = set()
    res : Set[str] = set()
    by_job: Dict[str, List[str]] = {}
    for p in j2r_paths:
        for r in read_csv_rows(p):
            j = str(r.get("job_id","")).strip()
            ri= str(r.get("resume_id","")).strip()
            if not j or not ri:
                continue
            edges.add((j,ri))
            jobs.add(j); res.add(ri)
            by_job.setdefault(j,[]).append(ri)
    return edges, jobs, res, by_job

# Load labels: (job_id, resume_id) -> 0/1 (eval only)
def load_labels(path: str) -> Dict[Tuple[str,str], int]:
    L: Dict[Tuple[str,str], int] = {}
    for r in read_csv_rows(path):
        j = str(r.get("job_id","")).strip()
        ri= str(r.get("resume_id","")).strip()
        lb= str(r.get("label","")).strip().lower()
        if j and ri:
            L[(j,ri)] = 1 if lb in ("1","true","yes") else 0
    return L

# ID maps
def build_id_maps(jobs: Iterable[str], resumes: Iterable[str]) -> Tuple[Dict[str,int], Dict[str,int]]:
    job2i = {j:i for i,j in enumerate(sorted(set(jobs)))}
    res2i = {r:i for i,r in enumerate(sorted(set(resumes)))}
    return job2i, res2i

# Eval metrics (P@K, nDCG@K, MAP@K) — pilot style
def eval_job_centric(job_top: Dict[str, List[Tuple[str,float]]],
                     labels: Dict[Tuple[str,str], int],
                     K: int = 10) -> Dict[str, Any]:
    jobs_scored = 0
    hit_sum, ndcg_sum, ap_sum = 0, 0.0, 0.0
    for j, lst in job_top.items():
        topk = lst[:K]
        rels = [labels.get((j,ri), None) for (ri,_) in topk]
        if all(v is None for v in rels):
            continue
        jobs_scored += 1
        # P@K
        hit_sum += sum(1 for v in rels if v == 1)
        # nDCG@K
        pos = 0; dcg = 0.0
        for rank, v in enumerate(rels, start=1):
            if v == 1:
                pos += 1
                dcg += 1.0 / math.log2(rank+1)
        idcg = sum(1.0 / math.log2(i+1) for i in range(1, pos+1))
        ndcg_sum += (dcg / idcg) if idcg > 0 else 0.0
        # MAP@K
        seen = 0; precs = []
        for rank, v in enumerate(rels, start=1):
            if v == 1:
                seen += 1
                precs.append(seen / rank)
        ap_sum += (sum(precs)/len(precs)) if precs else 0.0
    if jobs_scored == 0:
        return {"jobs_scored": 0, "p_at_10": None, "nDCG@10": None, "MAP@10": None}
    return {
        "jobs_scored": jobs_scored,
        "p_at_10": hit_sum / (10 * jobs_scored),
        "nDCG@10": ndcg_sum / jobs_scored,
        "MAP@10": ap_sum / jobs_scored,
    }

# Interactions from Stage-2 baselines (implicit positives)
inter_edges, job_ids, res_ids, by_job_stage2 = load_interactions([TFIDF_J2R, BM25_J2R])
labels = load_labels(LABELS)

print(f"Implicit edges: {len(inter_edges)} | Jobs: {len(job_ids)} | Resumes: {len(res_ids)}")

job2i, res2i = build_id_maps(job_ids, res_ids)
n_jobs, n_res = len(job2i), len(res2i)
n_nodes = n_jobs + n_res

# Convert edges to index pairs in unified [0..n_jobs+n_res)
def j_idx(j: str) -> int: return job2i[j]
def r_idx(r: str) -> int: return n_jobs + res2i[r]

edge_index: List[Tuple[int,int]] = []
edge_set_idx: Set[Tuple[int,int]] = set()
for (j,ri) in inter_edges:
    u = j_idx(j); v = r_idx(ri)
    edge_index.append((u,v))
    edge_index.append((v,u))  # undirected for propagation
    edge_set_idx.add((u,v))

edge_index_t = torch.tensor(edge_index, dtype=torch.long, device=device).t().contiguous()  # [2, E]

# --- Safety guards before training ---
missing = [p for p in [TFIDF_J2R, BM25_J2R] if not os.path.isfile(p)]
if missing:
    raise FileNotFoundError(f"Missing Stage-2 files: {missing}")

if n_jobs == 0 or n_res == 0 or len(edge_set_idx) == 0:
    raise RuntimeError(
        f"No interactions found. Check CSVs have columns job_id,resume_id and are non-empty. "
        f"(jobs={n_jobs}, resumes={n_res}, edges={len(edge_set_idx)})"
    )

if not os.path.isfile(LABELS):
    print("WARNING: labels_clean_top10_strict.csv not found — training will run, "
          "but early-stop validation will be uninformative and final metrics will be NA.")
else:
    print("Labels found:", LABELS)

# Optional: estimate dense score matrix size for awareness
est_pairs = n_jobs * n_res
print(f"Score matrix size (jobs×resumes) = {n_jobs}×{n_res} ≈ {est_pairs/1e6:.1f} M pairs "
      f"(~{4*est_pairs/1e9:.2f} GB if fully materialized in fp32).")


print("Edge index shape:", tuple(edge_index_t.shape))

# Negative sampler for BPR
all_job_idx = torch.arange(0, n_jobs, device=device)
all_res_idx = torch.arange(n_jobs, n_jobs+n_res, device=device)

def sample_bpr(batch_sz: int = 8192) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
    # pick random positive (job,res)
    pos_js = []
    pos_rs = []
    # to pick positives uniformly, we reuse edge_set_idx list
    pos_pairs = random.sample(list(edge_set_idx), k=min(batch_sz, len(edge_set_idx)))
    for (ju, rv) in pos_pairs:
        pos_js.append(ju)
        pos_rs.append(rv)
    pos_js = torch.tensor(pos_js, device=device)
    pos_rs = torch.tensor(pos_rs, device=device)
    # negatives: same job, random resume not in positives
    neg_rs = torch.empty_like(pos_rs)
    for i in range(len(pos_js)):
        j = pos_js[i].item()
        while True:
            rv = (n_jobs + random.randrange(n_res))
            if (j, rv) not in edge_set_idx:
                neg_rs[i] = rv
                break
    return pos_js, pos_rs, neg_rs

def normalized_adj(n_nodes: int, edges: List[Tuple[int,int]]) -> torch.Tensor:
    row = [u for (u,v) in edges]
    col = [v for (u,v) in edges]
    idx = torch.tensor([row, col], dtype=torch.long)
    val = torch.ones(len(edges), dtype=torch.float32)
    # degree
    deg = torch.zeros(n_nodes, dtype=torch.float32).scatter_add_(0, torch.tensor(row), torch.ones(len(row)))
    deg = deg.clamp(min=1.0)
    # D^{-1/2} A D^{-1/2}
    d_inv_sqrt = torch.pow(deg, -0.5)
    v = d_inv_sqrt[row] * val * d_inv_sqrt[col]
    A = torch.sparse_coo_tensor(idx, v, (n_nodes, n_nodes))
    return A.coalesce().to(device)

class LightGCN(nn.Module):
    def __init__(self, n_nodes: int, dim: int = 64, n_layers: int = 3):
        super().__init__()
        self.emb = nn.Embedding(n_nodes, dim)
        nn.init.xavier_uniform_(self.emb.weight)
        self.n_layers = n_layers
        self.A = None  # set later

    def set_adj(self, A: torch.Tensor):
        self.A = A

    def propagate(self) -> torch.Tensor:
        x_list = [self.emb.weight]
        x = self.emb.weight
        for _ in range(self.n_layers):
            x = torch.sparse.mm(self.A, x)
            x_list.append(x)
        return torch.stack(x_list, dim=0).mean(dim=0)  # mean of [x0..xL]

    def forward(self, idx_nodes: Optional[torch.Tensor] = None) -> torch.Tensor:
        if self.A is None:
            raise RuntimeError("Adjacency not set")
        # During training we use full-prop for stability (small L, sparse mm on GPU is OK)
        x = self.propagate()
        if idx_nodes is None:
            return x
        return x[idx_nodes]

def bpr_loss(u_emb: torch.Tensor, pos_emb: torch.Tensor, neg_emb: torch.Tensor, reg: float = 1e-4):
    # score = dot
    pos = torch.sum(u_emb * pos_emb, dim=1)
    neg = torch.sum(u_emb * neg_emb, dim=1)
    loss = -F.logsigmoid(pos - neg).mean()
    reg_term = reg * (u_emb.norm(2).pow(2) + pos_emb.norm(2).pow(2) + neg_emb.norm(2).pow(2)) / u_emb.size(0)
    return loss + reg_term

# --- Early-stopping config ---
MAX_EPOCHS   = 50
PATIENCE     = 6          # epochs without improvement
EVAL_EVERY   = 2          # validate every N epochs
MONITOR      = "MAP@10"   # choose: "MAP@10", "p_at_10", "nDCG@10"

VAL_JOBS_MAX = 800        # how many labelled jobs to sample for validation
NEG_CAND     = 800        # random negative resume candidates per job for validation

import copy, math, random
random.seed(42)
torch.manual_seed(42)

# --- Build labelled job index (which jobs have labels?) ---
jobs_with_labelled_resumes = {}
for (j, r), lb in labels.items():
    jobs_with_labelled_resumes.setdefault(j, set()).add(r)

labelled_jobs = list(jobs_with_labelled_resumes.keys())
random.shuffle(labelled_jobs)
val_jobs = labelled_jobs[:min(VAL_JOBS_MAX, len(labelled_jobs))]

inv_job2i = {v:k for k,v in job2i.items()}
inv_res2i = {v:k for k,v in res2i.items()}

def sampled_validation_metrics(X: torch.Tensor,
                               K: int = 10,
                               neg_cand: int = NEG_CAND) -> dict:
    """
    Fast proxy validation on a fixed subset of labelled jobs.
    For each job, rank among its labelled resumes (+) and ~neg_cand random resumes (-).
    Returns pilot-style metrics dict.
    """
    if len(val_jobs) == 0:
        return {"jobs_scored": 0, "p_at_10": None, "nDCG@10": None, "MAP@10": None}

    J = F.normalize(X[:n_jobs], p=2, dim=1)
    R = F.normalize(X[n_jobs:], p=2, dim=1)

    job_top = {}
    all_res_idx = list(range(n_res))

    for j in val_jobs:
        ji = job2i.get(j, None)
        if ji is None:
            continue

        # labelled candidates (can include 0/1 labels)
        labelled_res = list(jobs_with_labelled_resumes.get(j, []))
        if not labelled_res:
            continue

        labelled_idx = [res2i[r] for r in labelled_res if r in res2i]

        # random negatives (exclude labelled to avoid duplicates)
        negs = []
        need = max(0, neg_cand - len(labelled_idx))
        while len(negs) < need:
            ridx = random.randrange(n_res)
            if ridx not in labelled_idx:
                negs.append(ridx)

        cand_idx = list(set(labelled_idx + negs))
        if not cand_idx:
            continue

        jv = J[ji:ji+1]                                 # [1, d]
        Rc = R[torch.tensor(cand_idx, device=R.device)] # [C, d]
        sc = (jv @ Rc.t()).squeeze(0)                   # [C]

        topv, topi = torch.topk(sc, k=min(K, Rc.size(0)))
        top_pairs = []
        for p in range(topi.numel()):
            ridx = cand_idx[topi[p].item()]
            top_pairs.append((inv_res2i[ridx], float(topv[p].item())))
        job_top[j] = top_pairs

    return eval_job_centric(job_top, labels, K=K)

def _metric_value(m: dict, key: str) -> float:
    if not m or m.get("jobs_scored", 0) == 0:
        return float("-inf")
    if key == "MAP@10":
        return m.get("MAP@10", None) if m.get("MAP@10", None) is not None else float("-inf")
    if key == "p_at_10":
        return m.get("p_at_10", None) if m.get("p_at_10", None) is not None else float("-inf")
    if key == "nDCG@10":
        return m.get("nDCG@10", None) if m.get("nDCG@10", None) is not None else float("-inf")
    return float("-inf")

# --- LightGCN training with early stopping ---
A = normalized_adj(n_nodes, edge_index)

lgcn = LightGCN(n_nodes=n_nodes, dim=64, n_layers=3).to(device)
lgcn.set_adj(A)
opt = torch.optim.Adam(lgcn.parameters(), lr=2e-3)

best_metric = float("-inf")
best_state  = None
since_improve = 0

for ep in range(1, MAX_EPOCHS+1):
    lgcn.train()
    pos_js, pos_rs, neg_rs = sample_bpr(8192)
    x = lgcn()  # full propagate
    u = x[pos_js]
    pos = x[pos_rs]
    neg = x[neg_rs]
    loss = bpr_loss(u, pos, neg, reg=1e-4)
    opt.zero_grad()
    loss.backward()
    opt.step()

    if ep % EVAL_EVERY == 0 or ep == 1:
        with torch.no_grad():
            X_cur = lgcn().detach()
            m = sampled_validation_metrics(X_cur, K=10, neg_cand=NEG_CAND)
            val = _metric_value(m, MONITOR)
        print(f"[LightGCN] epoch {ep:02d}/{MAX_EPOCHS}  loss={loss.item():.4f}  val({MONITOR})={val:.4f}  jobs={m.get('jobs_scored',0)}")

        if val > best_metric + 1e-6:
            best_metric = val
            best_state  = copy.deepcopy(lgcn.state_dict())
            since_improve = 0
        else:
            since_improve += 1
            if since_improve >= PATIENCE:
                print(f"[LightGCN] Early stop at epoch {ep} (no improvement for {PATIENCE} evals).")
                break

# Restore best and export embeddings
if best_state is not None:
    lgcn.load_state_dict(best_state)
with torch.no_grad():
    X_lgcn = lgcn().detach()
print("[LightGCN] best", MONITOR, "=", best_metric if best_metric != float("-inf") else "NA")

class MeanSAGE(nn.Module):
    def __init__(self, n_nodes: int, in_dim: int = 64, hid: int = 64, out_dim: int = 64, dropout: float = 0.1):
        super().__init__()
        self.x0 = nn.Embedding(n_nodes, in_dim)  # learnable "features"
        nn.init.xavier_uniform_(self.x0.weight)
        self.lin1 = nn.Linear(in_dim*2, hid)
        self.lin2 = nn.Linear(hid*2, out_dim)
        self.dropout = nn.Dropout(dropout)
        # adjacency in COO
        self._adj = None
        self._deg = None

    def set_adj(self, idx: torch.Tensor, n_nodes: int):
        # idx: [2, E] directed edges (we built both directions already)
        self._adj = idx
        deg = torch.bincount(idx[0], minlength=n_nodes).clamp(min=1)
        self._deg = deg.to(self.x0.weight.device)

    def mean_agg(self, x: torch.Tensor) -> torch.Tensor:
        # x: [N, D]
        row, col = self._adj[0], self._adj[1]
        m = x[col]                             # messages from neighbors
        out = torch.zeros_like(x)
        out.index_add_(0, row, m)             # sum over neighbors
        out = out / self._deg.unsqueeze(1)    # mean
        return out

    def forward(self) -> torch.Tensor:
        x = self.x0.weight
        neigh = self.mean_agg(x)
        h1 = F.relu(self.lin1(torch.cat([x, neigh], dim=1)))
        h1 = self.dropout(h1)

        neigh2 = self.mean_agg(h1)
        h2 = self.lin2(torch.cat([h1, neigh2], dim=1))
        return h2  # final node embeddings

def train_sage_earlystop(adj_idx: torch.Tensor,
                         n_nodes: int,
                         epochs: int = MAX_EPOCHS,
                         batch: int = 8192,
                         lr: float = 3e-3,
                         weight_decay: float = 1e-5):
    sage = MeanSAGE(n_nodes=n_nodes, in_dim=64, hid=64, out_dim=64).to(device)
    sage.set_adj(adj_idx, n_nodes)
    opt = torch.optim.Adam(sage.parameters(), lr=lr, weight_decay=weight_decay)

    best_metric = float("-inf")
    best_state  = None
    since_improve = 0

    for ep in range(1, epochs+1):
        sage.train()
        pos_js, pos_rs, neg_rs = sample_bpr(batch)
        x = sage()
        u = x[pos_js]
        pos = x[pos_rs]
        neg = x[neg_rs]
        loss = bpr_loss(u, pos, neg, reg=1e-4)
        opt.zero_grad()
        loss.backward()
        opt.step()

        if ep % EVAL_EVERY == 0 or ep == 1:
            with torch.no_grad():
                X_cur = sage().detach()
                m = sampled_validation_metrics(X_cur, K=10, neg_cand=NEG_CAND)
                val = _metric_value(m, MONITOR)
            print(f"[GraphSAGE] epoch {ep:02d}/{epochs}  loss={loss.item():.4f}  val({MONITOR})={val:.4f}  jobs={m.get('jobs_scored',0)}")

            if val > best_metric + 1e-6:
                best_metric = val
                best_state  = copy.deepcopy(sage.state_dict())
                since_improve = 0
            else:
                since_improve += 1
                if since_improve >= PATIENCE:
                    print(f"[GraphSAGE] Early stop at epoch {ep} (no improvement for {PATIENCE} evals).")
                    break

    if best_state is not None:
        sage.load_state_dict(best_state)

    with torch.no_grad():
        X = sage().detach()
    print("[GraphSAGE] best", MONITOR, "=", best_metric if best_metric != float("-inf") else "NA")
    return X

# Train GraphSAGE with early stopping
X_sage = train_sage_earlystop(edge_index_t, n_nodes=n_nodes, epochs=MAX_EPOCHS, batch=8192)

# Helpers to convert embeddings to scores and top-10 lists (job- and resume-centric)
def split_views(X: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
    J = X[:n_jobs]      # [n_jobs, d]
    R = X[n_jobs:]      # [n_res, d]
    J = F.normalize(J, p=2, dim=1)
    R = F.normalize(R, p=2, dim=1)
    return J, R

def rank_job_to_resumes(J: torch.Tensor, R: torch.Tensor, topk: int = 10,
                        max_block_bytes: int = 512*1024*1024) -> Dict[str, List[Tuple[str, float]]]:
    """
    Chunked J @ R^T top-k per job. Keeps memory under ~max_block_bytes.
    """
    inv_res2i = {v:k for k,v in res2i.items()}
    inv_job2i = {v:k for k,v in job2i.items()}
    job_top: Dict[str, List[Tuple[str, float]]] = {}

    bytes_per_score = 4  # float32
    nR = R.size(0)
    # block_size * nR * 4 bytes <= max_block_bytes
    block_size = max(1, int(max_block_bytes // (bytes_per_score * max(1, nR))))

    for start in range(0, n_jobs, block_size):
        end = min(n_jobs, start + block_size)
        scores = J[start:end] @ R.t()  # [B, n_res] on device
        topv, topi = torch.topk(scores, k=min(topk, nR), dim=1)
        for bi in range(end - start):
            ji = start + bi
            j = inv_job2i[ji]
            lst = []
            for rpos in range(topi.shape[1]):
                ri = topi[bi, rpos].item()
                sc = topv[bi, rpos].item()
                lst.append((inv_res2i[ri], float(sc)))
            job_top[j] = lst
        del scores, topv, topi
        torch.cuda.empty_cache()
    return job_top

def rank_resume_to_jobs(J: torch.Tensor, R: torch.Tensor, topk: int = 10,
                        max_block_bytes: int = 512*1024*1024) -> Dict[str, List[Tuple[str,float]]]:
    """
    Chunked R @ J^T top-k per resume. Keeps memory under ~max_block_bytes.
    """
    inv_res2i = {v:k for k,v in res2i.items()}
    inv_job2i = {v:k for k,v in job2i.items()}
    res_top: Dict[str, List[Tuple[str, float]]] = {}

    bytes_per_score = 4
    nJ = J.size(0)
    block_size = max(1, int(max_block_bytes // (bytes_per_score * max(1, nJ))))

    for start in range(0, n_res, block_size):
        end = min(n_res, start + block_size)
        scores = R[start:end] @ J.t()  # [B, n_jobs]
        topv, topi = torch.topk(scores, k=min(topk, nJ), dim=1)
        for bi in range(end - start):
            ri = start + bi
            r = inv_res2i[ri]
            lst = []
            for jpos in range(topi.shape[1]):
                ji = topi[bi, jpos].item()
                sc = topv[bi, jpos].item()
                lst.append((inv_job2i[ji], float(sc)))
            res_top[r] = lst
        del scores, topv, topi
        torch.cuda.empty_cache()
    return res_top

def save_job2res_csv(path: str, job_top: Dict[str, List[Tuple[str,float]]], source_name: str):
    rows: List[Dict[str,Any]] = []
    for j, lst in job_top.items():
        for rank, (rid, sc) in enumerate(lst, start=1):
            rows.append({"job_id": j, "resume_id": rid, "score": f"{sc:.6f}", "rank": rank, "source": source_name})
    write_csv_rows(path, rows, header=["job_id","resume_id","score","rank","source"])

def save_res2job_csv(path: str, res_top: Dict[str, List[Tuple[str,float]]], source_name: str):
    rows: List[Dict[str,Any]] = []
    for r, lst in res_top.items():
        for rank, (jid, sc) in enumerate(lst, start=1):
            rows.append({"resume_id": r, "job_id": jid, "score": f"{sc:.6f}", "rank": rank, "source": source_name})
    write_csv_rows(path, rows, header=["resume_id","job_id","score","rank","source"])

# --- LightGCN rankings & metrics ---
J_l, R_l = split_views(X_lgcn)
job_top_l = rank_job_to_resumes(J_l, R_l, topk=10)
res_top_l = rank_resume_to_jobs(J_l, R_l, topk=10)
save_job2res_csv(OUT_LGCN_J2R, job_top_l, "lightgcn")
save_res2job_csv(OUT_LGCN_R2J, res_top_l, "lightgcn")
m_l = eval_job_centric(job_top_l, labels, K=10)
print("[LightGCN] metrics:", m_l)

# --- GraphSAGE rankings & metrics ---
J_s, R_s = split_views(X_sage)
job_top_s = rank_job_to_resumes(J_s, R_s, topk=10)
res_top_s = rank_resume_to_jobs(J_s, R_s, topk=10)
save_job2res_csv(OUT_SAGE_J2R, job_top_s, "graphsage")
save_res2job_csv(OUT_SAGE_R2J, res_top_s, "graphsage")
m_s = eval_job_centric(job_top_s, labels, K=10)
print("[GraphSAGE] metrics:", m_s)

# --- Append to overall_metrics_true.csv ---
def append_overall(path: str, source: str, mm: Dict[str,Any]):
    exists = os.path.isfile(path)
    row = {
        "source": source,
        "p_at_10": "" if mm["p_at_10"] is None else f"{mm['p_at_10']:.4f}",
        "nDCG@10": "" if mm["nDCG@10"] is None else f"{mm['nDCG@10']:.4f}",
        "MAP@10":  "" if mm["MAP@10"]  is None else f"{mm['MAP@10']:.4f}",
        "jobs_scored": mm["jobs_scored"]
    }
    if not exists:
        write_csv_rows(path, [row], ["source","p_at_10","nDCG@10","MAP@10","jobs_scored"])
    else:
        prev = read_csv_rows(path)
        prev.append(row)
        write_csv_rows(path, prev, ["source","p_at_10","nDCG@10","MAP@10","jobs_scored"])

append_overall(OVERALL_TRUE, "lightgcn", m_l)
append_overall(OVERALL_TRUE, "graphsage", m_s)

print("Saved:")
print("  ", OUT_LGCN_J2R)
print("  ", OUT_LGCN_R2J)
print("  ", OUT_SAGE_J2R)
print("  ", OUT_SAGE_R2J)
print("  ", OVERALL_TRUE)

